# cs231n  随笔（以图片记录为主）

![image-20221119233056040](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221119233056040.png)

![image-20221119233109477](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221119233109477.png)

![image-20221119233849736](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221119233849736.png)

![image-20221119234202499](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221119234202499.png)

![image-20221119235625050](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221119235625050.png)

![image-20221120000053728](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221120000053728.png)

![image-20221120232101328](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221120232101328.png)

![image-20221120234240789](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221120234240789.png)

例如x为5000 * 32 * 32 * 3的数组，则x.shape[0]=5000 , x.shape[1]=32 , x.shape[2]=32 , x.shape[3]=3

![image-20221120234746564](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221120234746564.png)

![image-20221121090454510](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221121090454510.png)

```python
a=a.reshape(a.shape[0],-1)
a=np.reshape(a,(a.shape[0],-1))
```

![image-20221121093514024](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221121093514024.png)

![image-20221121131636527](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221121131636527.png)

![image-20221121133817348](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221121133817348.png)

![image-20221121134207024](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221121134207024.png)

对于二维数组而言，axis=0代表对列操作，axis=1代表对行操作

![image-20221121142437963](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221121142437963.png)

np.sum之后变为一维数组，需要加上参数 keepdims=True

![image-20221121143510790](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221121143510790.png)

## 11.21

![image-20221123235232620](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221123235232620.png)

![image-20221123235851274](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221123235851274.png)

np.split使得数组分割为列表，np.concatenate使得列表拼接为数组

## 12.2

![image-20221202172231173](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221202172231173.png)

结果是列数加1

![image-20221203153030134](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221203153030134.png)

![image-20221203153043996](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221203153043996.png)

## 12.6

向前传递的梯度等于上游传下来的梯度值乘以**自身**在该处的导数值

SGD：随机梯度下降

![image-20221206203420151](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20221206203420151.png)

np.std()默认是有偏的，即分母除以n，要变成无偏的，将ddof设置为1

同样的,np.var()亦是有偏的

## 1.23

![image-20230123161424037](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230123161424037.png)

权重矩阵的初始化至关重要：

- 过小时，由于不断相乘，梯度衰减到0，无法学习
- 过大时，梯度爆炸，神经元死亡，无法学习
- 网络越深，对weight_scale的变化越敏感（每一层都相乘）



### SGD + Momentum

通常指 Nesterov Momentum

![image-20230123164324710](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230123164324710.png)

 代码如下：

```python
v = config["momentum"]*v - config["learning_rate"]*dw
next_w = w+v
```



### RMSprop

```python
config['cache'] = config['decay_rate']*config['cache'] + (1-config['decay_rate'])*dw*dw
next_w = w - config['learning_rate']*dw/(np.sqrt(config['cache']) + config['epsilon'])
```



### Adam

```python
config['t'] += 1
config['m'] = config['beta1']*config['m'] + (1-config['beta1'])*dw
config['v'] = config['beta2']*config['v'] + (1-config['beta2'])*dw*dw
mt = config['m']/(1-config['beta1']**config['t']) #注意这里无偏化不更新config['m']
vt = config['v']/(1-config['beta2']**config['t'])
next_w = w - config['learning_rate']*mt/(np.sqrt(vt) + config['epsilon'])
pass
```



## 1.25  BaychNormalization

![image-20230125150502311](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230125150502311.png)

反向传播用于训练过程中，因此这时的$\mu$一定是样本自身的均值而非训练后生成的用于测试的均值，因此在求导时需要考虑这一项（方差$\sigma$同理）

- 矩阵求导就是对应项求导（$\frac{dL}{dx}$，求对某个$x_{ij}$的导数 ：==>$f$中所有含$x_{ij}$的项如$f_{mn}$,其贡献为$\frac{dL}{df_{mn}}\cdot\frac{df_{mn}}{dx_{ij}}$,对所有这样的$f_{mn}$求和，即为$\frac{dL}{dx_{ij}}$）
- 上游导数对应的值乘以本地导数值再求和
- 注意矩阵的size，从二维到一维一般是求和(对于广播后相乘的矩阵都是如此)
- 原矩阵广播==>导数矩阵也是广播，故原矩阵求和降维则导数矩阵求和降维



## 1.26  layer normalization

bn是对所有图像的某一个像素做平均，ln是对一个图像（某一通道）的所有像素做平均，即对特征做均值化

![img](https://img-blog.csdnimg.cn/20190208203843638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTg4MDU3OQ==,size_16,color_FFFFFF,t_70)

注意即为一个转置关系

## 1.27  bn梯度推导

![image-20230130143025281](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230130143025281.png)

![image-20230130143037813](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230130143037813.png)

代码如下：

```python
out_norm, gamma, std = cache
dbeta = np.sum(dout, axis=0)
dgamma = np.sum(dout*out_norm, axis=0)
dout_norm = dout*gamma
N,D = dout.shape
# dvar = np.sum(dout_norm*(-0.5)*out_norm/std**2, axis=0)
# dmu = -np.sum(dout_norm/std, axis=0)
# dx = dout_norm/std + dvar*std*out_norm*2/N + dmu/N
dx = (dout - (dgamma*out_norm + dbeta)/N)*gamma/std
```



## 1.27  之前的笔记

![image-20230130152652334](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230130152652334.png)

![image-20230130152703137](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230130152703137.png)

![image-20230130152710920](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230130152710920.png)

## 1.27  dropout

![image-20230130170525481](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230130170525481.png)

## 2.1  GPU

GPU存在于显卡中，显卡包括了GPU和显存等

GPU适合高度的并发计算（多核）

CUDA是NVIDIA基于GPU运算的编程语言（类C）

Numpy只能运行于CPU

### TensorFlow

首先定义变量及计算图，无需对变量赋值，计算图只是声明了一些逻辑，若要求梯度，会在计算图中加入一些额外的辅助逻辑，但始终没有真正的计算

定义完成后进入有个Tensorflow的session,在这个session中具体为计算图中的变量赋值，并执行计算

![image-20230201200251869](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230201200251869.png)

如果将w1和w2在计算图中作为占位符，训练过程中会不断在CPU和GPU之间传输数据，耗时且浪费资源(numpy只能在CPU上运行)，改进想法，将w1和w2作为变量存储在计算图中

注意此时需要初始化

![image-20230201200839071](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230201200839071.png)

更新操作也应体现在计算图中

## 2.5  cnn

![image-20230205170559189](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230205170559189.png)

## 2.10  spatial batch normalization

numpy中transpose函数，将矩阵维度换序

## 2.10  Group Normalization

![img](https://upload-images.jianshu.io/upload_images/12522150-02baf749c0d7a33b.png?imageMogr2/auto-orient/strip|imageView2/2/w/782/format/webp)

![image-20230210225004596](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230210225004596.png)

## Why GN work

上面三节分别介绍了BN的问题，以及GN的工作方式，本节将介绍GN work的原因。

传统角度来讲，在深度学习没有火起来之前，提取特征通常是使用SIFT，HOG和GIST特征，这些特征有一个共性，都具有按group表示的特性，每一个group由相同种类直方图的构建而成，这些特征通常是对在每个直方图（histogram）或每个方向（orientation）上进行组归一化（group-wise norm）而得到。而更高维的特征比如VLAD和Fisher Vectors(FV)也可以看作是group-wise feature，此处的group可以被认为是每个聚类（cluster）下的子向量sub-vector。

从深度学习上来讲，完全可以认为卷积提取的特征是一种非结构化的特征或者向量，拿网络的第一层卷积为例，卷积层中的的卷积核filter1和此卷积核的其他经过transform过的版本filter2（transform可以是horizontal flipping等），在同一张图像上学习到的特征应该是具有相同的分布，那么，具有相同的特征可以被分到同一个group中，按照个人理解，每一层有很多的卷积核，这些核学习到的特征并不完全是独立的，某些特征具有相同的分布，因此可以被group。

导致分组（group）的因素有很多，比如频率、形状、亮度和纹理等，HOG特征根据orientation分组，而对神经网络来讲，其提取特征的机制更加复杂，也更加难以描述，变得不那么直观。另在神经科学领域，一种被广泛接受的计算模型是对cell的响应做归一化，此现象存在于浅层视觉皮层和整个视觉系统。

作者基于此，提出了组归一化（Group Normalization）的方式，且效果表明，显著优于BN、LN、IN等。

GN的归一化方式避开了batch size对模型的影响，特征的group归一化同样可以解决$Internal$ $Covariate$ $Shift$的问题，并取得较好的效果。



## 2.11  pytorch

```python
device = torch.device('cpu')
# device = torch.device('cuda') # Uncomment this to run on GPU
```

标准正态分布：torch.randn()

矩阵相乘：x.mm(y)

![image-20230211194744017](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230211194744017.png)

实现relu: x.clamp(min=0)

幂：x.pow(2)   转置：x.t()  

![image-20230211195043131](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230211195043131.png)

注意，计算出的loss仍为张量，需用item函数返回浮点数

The **autograd** package in PyTorch provides exactly this functionality. When using autograd, the forward pass of your network will define a **computational graph**; nodes in the graph will be Tensors, and edges will be functions that produce output Tensors from input Tensors. Backpropagating through this graph then allows you to easily compute gradients.

```python
# Use autograd to compute the backward pass. This call will compute the
# gradient of loss with respect to all Tensors with requires_grad=True.
# After this call w1.grad and w2.grad will be Tensors holding the gradient
# of the loss with respect to w1 and w2 respectively.
loss.backward()

# Update weights using gradient descent. For this step we just want to mutate
# the values of w1 and w2 in-place; we don't want to build up a computational
# graph for the update steps, so we use the torch.no_grad() context manager
# to prevent PyTorch from building a computational graph for the updates
with torch.no_grad():
    w1 -= learning_rate * w1.grad
    w2 -= learning_rate * w2.grad
#torch.no_grad()  计算梯度但不把梯度加入计算图

# Manually zero the gradients after running the backward pass
w1.grad.zero_()
w2.grad.zero_()
```



```python
# Code in file autograd/two_layer_net_custom_function.py
import torch

class MyReLU(torch.autograd.Function):
  """
  We can implement our own custom autograd Functions by subclassing
  torch.autograd.Function and implementing the forward and backward passes
  which operate on Tensors.
  """
  @staticmethod
  def forward(ctx, x):
    """
    In the forward pass we receive a context object and a Tensor containing the
    input; we must return a Tensor containing the output, and we can use the
    context object to cache objects for use in the backward pass.
    """
    ctx.save_for_backward(x)
    return x.clamp(min=0)

  @staticmethod
  def backward(ctx, grad_output):
    """
    In the backward pass we receive the context object and a Tensor containing
    the gradient of the loss with respect to the output produced during the
    forward pass. We can retrieve cached data from the context object, and must
    compute and return the gradient of the loss with respect to the input to the
    forward function.
    """
    x, = ctx.saved_tensors
    grad_x = grad_output.clone()
    grad_x[x < 0] = 0
    return grad_x


device = torch.device('cpu')
# device = torch.device('cuda') # Uncomment this to run on GPU

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold input and output
x = torch.randn(N, D_in, device=device)
y = torch.randn(N, D_out, device=device)

# Create random Tensors for weights.
w1 = torch.randn(D_in, H, device=device, requires_grad=True)
w2 = torch.randn(H, D_out, device=device, requires_grad=True)

learning_rate = 1e-6
for t in range(500):
  # Forward pass: compute predicted y using operations on Tensors; we call our
  # custom ReLU implementation using the MyReLU.apply function
  y_pred = MyReLU.apply(x.mm(w1)).mm(w2)
 
  # Compute and print loss
  loss = (y_pred - y).pow(2).sum()
  print(t, loss.item())

  # Use autograd to compute the backward pass.
  loss.backward()

  with torch.no_grad():
    # Update weights using gradient descent
    w1 -= learning_rate * w1.grad
    w2 -= learning_rate * w2.grad

    # Manually zero the gradients after running the backward pass
    w1.grad.zero_()
    w2.grad.zero_()
```

 The biggest difference between the two is that TensorFlow's computational graphs are **static** and PyTorch uses **dynamic** computational graphs.



### torch.nn

```python
# Use the nn package to define our model as a sequence of layers. nn.Sequential
# is a Module which contains other Modules, and applies them in sequence to
# produce its output. Each Linear Module computes output from input using a
# linear function, and holds internal Tensors for its weight and bias.
# After constructing the model we use the .to() method to move it to the
# desired device.
model = torch.nn.Sequential(
          torch.nn.Linear(D_in, H),
          torch.nn.ReLU(),
          torch.nn.Linear(H, D_out),
        ).to(device)

# The nn package also contains definitions of popular loss functions; in this
# case we will use Mean Squared Error (MSE) as our loss function. Setting
# reduction='sum' means that we are computing the *sum* of squared errors rather
# than the mean; this is for consistency with the examples above where we
# manually compute the loss, but in practice it is more common to use mean
# squared error as a loss by setting reduction='elementwise_mean'.
loss_fn = torch.nn.MSELoss(reduction='sum')

# Forward pass: compute predicted y by passing x to the model. Module objects
# override the __call__ operator so you can call them like functions. When
# doing so you pass a Tensor of input data to the Module and it produces
# a Tensor of output data.
y_pred = model(x)

# Compute and print loss. We pass Tensors containing the predicted and true
# values of y, and the loss function returns a Tensor containing the loss.
loss = loss_fn(y_pred, y)
print(t, loss.item())

# Zero the gradients before running the backward pass.
model.zero_grad()

# Backward pass: compute gradient of the loss with respect to all the learnable
# parameters of the model. Internally, the parameters of each Module are stored
# in Tensors with requires_grad=True, so this call will compute gradients for
# all learnable parameters in the model.
loss.backward()

# Update the weights using gradient descent. Each parameter is a Tensor, so
# we can access its data and gradients like we did before.
with torch.no_grad():
    for param in model.parameters():
        param.data -= learning_rate * param.grad
```



## 2.11  关于python中的`with`：

with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭／线程中锁的自动获取和释放等。

总结with工作原理：
（１）紧跟with后面的语句被求值后，返回对象的“–enter–()”方法被调用，这个方法的返回值将被赋值给as后面的变量；
（２）当with后面的代码块全部被执行完之后，将调用前面返回对象的“–exit–()”方法。

## 2.11  torch.no_grad()

在pytorch中，tensor有一个requires_grad参数，如果设置为True，则反向传播时，该tensor就会自动求导。tensor的requires_grad的属性默认为False,若一个节点（叶子变量：自己创建的tensor）requires_grad被设置为True，那么所有依赖它的节点requires_grad都为True（即使其他相依赖的tensor的requires_grad = False）

当requires_grad设置为False时,反向传播时就不会自动求导了，因此大大节约了显存或者说内存。

### with torch.no_grad的作用

在该模块下，所有计算得出的tensor的requires_grad都自动设置为False。

即使一个tensor（命名为x）的requires_grad = True，在with torch.no_grad计算，由x得到的新tensor（命名为w-标量）requires_grad也为False，且grad_fn也为None,即不会对w求导。

- 用于停止autograd模块的工作，起到加速和节省显存的作用（具体行为就是停止gradient计算，从而节省了GPU算力和显存）
- 不会影响dropout和batchnorm层的行为

在with语句中，使用之前计算出的梯度进行变量的更新，但不需要再对更新后的变量计算梯度，因此使用no_grad()



## 2.12    module

```python
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
# Before the backward pass, use the optimizer object to zero all of the
# gradients for the Tensors it will update (which are the learnable weights
# of the model)
optimizer.zero_grad()

# Backward pass: compute gradient of the loss with respect to model parameters
loss.backward()

# Calling the step function on an Optimizer makes an update to its parameters
optimizer.step()
```

Sometimes you will want to specify models that are more complex than a sequence of existing Modules; for these cases you can define your own Modules by subclassing `nn.Module` and defining a `forward` which receives input Tensors and produces output Tensors using other modules or other autograd operations on Tensors.

定义新的module，需define init和forward

```python
def flatten(x):
    N = x.shape[0] # read in N, C, H, W
    return x.view(N, -1)  # "flatten" the C * H * W values into a single vector per image
```

![image-20230213124541709](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20230213124541709.png)



For simple models like a stack of feed forward layers, you still need to go through 3 steps: subclass `nn.Module`, assign layers to class attributes in `__init__`, and call each layer one by one in `forward()`.

PyTorch provides a container Module called `nn.Sequential`, which merges the above steps into one. It is not as flexible as `nn.Module`, because you cannot specify more complex topology than a feed-forward stack, but it's good enough for many use cases.
